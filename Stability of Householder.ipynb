{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stability of Householder Triangularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004938420359901829,9.94724397121888e-5,7.015158696105438e-16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random upper-triangular matrix\n",
    "R = triu(rand(50,50));\n",
    "\n",
    "# Construct a random orthogonal matrix\n",
    "Q,X = qr(rand(50,50));\n",
    "\n",
    "# Build a matrix with known QR factorization\n",
    "A = Q*R;\n",
    "\n",
    "# Compute QR factorization with Householder Triangularization\n",
    "Q2,R2 = qr(A);\n",
    "\n",
    "# Compare errors\n",
    "norm(Q2-Q), norm(R2-R)/norm(R), norm(A-Q2*R2)/norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how large the first two errors are compared with the last term!  Somehow even though $Q_2$ and $R_2$ are terrible approximations of $Q$ and $R$, their product $Q_2R_2$ is a surprising approximation of $QR$.  Somehow, the errors introduced in $Q_2$ and $R_2$ are highly correlated and cancel out in the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate how special this cancellation of errors is, we construct another pair of matrices which are small perturbations of $Q$ and $R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2158685459599515e-6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute two slight perturbations of Q and R\n",
    "Q3 = Q+1e-6*rand(50,50);\n",
    "R3 = R+1e-6*rand(50,50);\n",
    "\n",
    "# Find the error\n",
    "norm(A-Q3*R3)/norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time, the error is massive, even though $Q_3$ and $R_3$ are 'just as bad' an approximation of $Q$ and $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The errors in $Q_2$ and $R_2$ are _forward errors_.  In general, a large forward error can be the result of an ill-conditioned problem or an unstable algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The error in $Q_2R_2$ is the _backward error_ or _residual_.  The smallness of this error suggests that Householder triangularization is backwards stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The result of Householder triangularization will take the form: $$\\tilde Q \\tilde R = A + \\delta A,$$ for some small $\\delta A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Where $\\tilde R$ is the upper-triangular matrix that is constructed by Householder triangularization in floating point arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, $\\tilde Q$ will be an _exactly unitary_ matrix.   Recall $Q=Q_1Q_2\\cdots Q_n$ is a product of Householder reflectors defined by vectors $\\mathbf{v}_k$.  In floating point arithmetic we obtain, instead, a sequence $\\tilde{\\mathbf{v}}_k$ of computed vectors.  Let $\\tilde Q_k$ denote the _exactly unitary_ reflector defined **mathematically** not numerically, by $\\tilde{\\mathbf{v}}_k$.  Then set $\\tilde Q = \\tilde Q_1\\cdots \\tilde Q_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ** THEOREM. ** Let the QR factorization $A=QR$ of a matrix $A\\in\\mathbb{C}^{m\\times n}$ be computed by Householder triangularization, and let the computed factors $\\tilde Q$ and $\\tilde R$ be defined as above. Then we have: $$\\tilde Q \\tilde R = A + \\delta A, \\quad \\frac{\\|\\delta A \\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}})$$ for some $\\delta A \\in \\mathbb{C}^{m\\times n}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyzing an Algorithm to Solve $A\\mathbf{x} = \\mathbf{b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally, QR factorization is not an end in itself.  In particular, it is usually a part of a larger algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We know that the QR facotrization algorithm via Householder triangularization is backwards compatible, however, is it stable enough for use in other algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As an example we consider the algorithm of solving a linear system via the QR factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[0.487946; 0.323111; … ; 0.93473; 0.203352],\n",
       "\n",
       "[0.487946; 0.323111; … ; 0.93473; 0.203352])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a given linear system Ax=b\n",
    "b = rand(50,1);\n",
    "A = rand(50,50);\n",
    "\n",
    "# Factor A into QR\n",
    "Q,R = qr(A);\n",
    "\n",
    "# Construct Q'b\n",
    "y = Q'*b;\n",
    "\n",
    "# Solve the triangular system by back substitution\n",
    "x = R\\y;\n",
    "\n",
    "b, Q*R*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We prove this algorithm is backwards stable by proving each of the three steps is backwards stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first step is QR factorization, leading to matrices $\\tilde R$ and $\\tilde Q$.   We already know this is backwards stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second step is the computation $\\tilde Q^* \\mathbf{b}$.  Notice that we are now working with the computed $\\tilde Q$, not $Q$.\n",
    "\n",
    "When $\\tilde Q^* \\mathbf{b}$ is computed, rounding errors will be introduced, hence the result will not be exactly $\\tilde Q^* \\mathbf{b}$.  Instead it will be some $\\tilde{\\mathbf{y}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One shows (exercise!) that: $$(\\tilde Q + \\delta Q) \\tilde{\\mathbf{y}} = \\mathbf{b}, \\quad \\|\\delta Q\\| = O(\\epsilon_{\\text{machine}}).$$\n",
    "\n",
    "That is, applying the Householder reflectors in floating point arithmetic is exactly equivalent to multiplying $\\mathbf{b}$ by a slightly perturbed matrix $(\\tilde Q + \\delta Q)^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The final step of this algorithm is back substitution to compute $\\tilde{R}^{-1}\\tilde{\\mathbf{y}}$.  New rounding errors will be introduced.  The estimate in this case (not obvious!): \n",
    "\n",
    "$$(\\tilde R + \\delta R) \\tilde{\\mathbf{x}} = \\tilde{\\mathbf{y}}, \\quad \\frac{\\|\\delta R\\|}{\\|\\tilde R\\|} = O(\\epsilon_{\\text{machine}}).$$\n",
    "\n",
    "In words, this asserts that the floating point result $\\tilde x$ is exactly the solution of a slight perturbation of $\\tilde R\\mathbf{x} =\\tilde{\\mathbf{y}}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ** THEOREM. ** Solving $A\\mathbf{x} = \\mathbf{b}$ via QR factorization is backwards stable, satisfying: $$(A+\\Delta A) \\tilde{\\mathbf{x}} = \\mathbf{b},\\quad \\frac{\\|\\Delta A\\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}}),$$ for some $\\Delta A \\in \\mathbb{C}^{m\\times m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Proof. ** \n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\mathbf{b} = (\\tilde Q+\\delta Q) (\\tilde R + \\delta R) \\tilde{\\mathbf{x}} = \\left[\\tilde Q\\tilde R + (\\delta Q) \\tilde R + \\tilde Q (\\delta R) + (\\delta Q)(\\delta R)\\right] \\tilde{\\mathbf{x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By the previous theorem:\n",
    "\n",
    "$$\\mathbf{b} = \\left[A + \\delta A + (\\delta Q)\\tilde R + \\tilde Q (\\delta R) + (\\delta Q)(\\delta R)\\right]\\tilde{\\mathbf{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which has the form:\n",
    "\n",
    "$$\n",
    "\\mathbf{b} = (A + \\Delta A) \\tilde{\\mathbf{x}},\n",
    "$$\n",
    "where $\\Delta A$ is the above sum of 4 terms.\n",
    "\n",
    "We now need to bound the error term $\\Delta A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since $\\tilde Q \\tilde R = A + \\delta A$ and $\\tilde Q$ is unitary:\n",
    "\n",
    "$$\\frac{\\|\\tilde R\\|}{\\|A\\|} \\leq \\|\\tilde Q^*\\| \\frac{\\|A+\\delta A\\|}{\\|A\\|} = O(1),$$ as $\\epsilon_{\\text{machine}}\\to 0$ (by Theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This implies:\n",
    "\n",
    "$$\n",
    "\\frac{\\|(\\delta Q) \\tilde R\\|}{\\|A\\|} \\leq \\|\\delta Q\\| \\frac{\\|\\tilde R\\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Similarly:\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\tilde Q (\\delta R)\\|}{\\|A\\|} \\leq \\|\\tilde Q\\| \\frac{\\|\\delta R\\|}{\\|\\tilde R\\|}\\frac{\\|\\tilde R\\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally,\n",
    "\n",
    "$$\n",
    "\\frac{\\|(\\delta Q) (\\delta R)\\|}{\\|A\\|} \\leq \\|\\delta Q\\| \\frac{\\|\\delta R\\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}}^2).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Therefore the total perturbation $\\Delta A$ satisfies:\n",
    "\n",
    "$$\n",
    "\\frac{\\|\\Delta A\\|}{\\|A\\|} \\leq \\frac{\\|\\delta A\\|}{\\|A\\|} + \\frac{\\|(\\delta Q)\\tilde R\\|}{\\|A\\|}+ \\frac{\\|\\tilde Q (\\delta R)\\|}{\\|A\\|}+ \\frac{\\|(\\delta Q )(\\delta R)\\|}{\\|A\\|} = O(\\epsilon_{\\text{machine}}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Combining this result with our general theory of backwards stable algorithms and conditioning of matrix problems, we deduce:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ** THEOREM. ** The computed solution $\\tilde{\\mathbf{x}}$ to the system $A\\mathbf{x} = \\mathbf{b}$ using the above algorithm satisfies: $$\\frac{\\|\\tilde{\\mathbf{x}} - \\mathbf{x} \\|}{\\|\\mathbf{x}\\|} = O(\\kappa(A) \\epsilon_{\\text{machine}}).$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
